{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4\n",
    "Keras offers the possibility to call a function at each epoch. These are Callbacks, and their documentation is here. Callbacks allow us to add some neat functionality. In this exercise we'll explore a few of them.\n",
    "\n",
    "- Split the data into train and test sets with a test_size = 0.3 and random_state=42\n",
    "- Reset and recompile your model\n",
    "- train the model on the train data using validation_data=(X_test, y_test)\n",
    "- Use the EarlyStopping callback to stop your training if the val_loss doesn't improve\n",
    "- Use the ModelCheckpoint callback to save the trained model to disk once training is finished\n",
    "- Use the TensorBoard callback to output your training information to a /tmp/ subdirectory\n",
    "- Watch the next video for an overview of tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as kb\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import he_normal\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filepath_or_buffer=r'./wine.csv')\n",
    "stdsclr = StandardScaler()\n",
    "\n",
    "X = data.drop(columns=['Class'])\n",
    "X = stdsclr.fit_transform(X)\n",
    "y = data['Class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train,y_val = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckeckpoint = ModelCheckpoint(filepath='./checkpoint/weights.hdf5', save_best_only=True, verbose=1)\n",
    "early_stoper = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir='./tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 1.0855 - acc: 0.3387 - val_loss: 1.0105 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.44554\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.9420 - acc: 0.4194 - val_loss: 0.8450 - val_acc: 0.3889\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.44554\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.7957 - acc: 0.4435 - val_loss: 0.7368 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.44554\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.7217 - acc: 0.6855 - val_loss: 0.6737 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44554\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6694 - acc: 0.7661 - val_loss: 0.6021 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44554\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.5589 - acc: 0.9113 - val_loss: 0.4885 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44554\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.4369 - acc: 0.9597 - val_loss: 0.3534 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44554 to 0.35338, saving model to ./checkpoint/weights.hdf5\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.3152 - acc: 0.9758 - val_loss: 0.2543 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35338 to 0.25430, saving model to ./checkpoint/weights.hdf5\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.2345 - acc: 0.9839 - val_loss: 0.1757 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25430 to 0.17574, saving model to ./checkpoint/weights.hdf5\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.1784 - acc: 0.9839 - val_loss: 0.1345 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.17574 to 0.13453, saving model to ./checkpoint/weights.hdf5\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.1299 - acc: 0.9919 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.13453 to 0.10322, saving model to ./checkpoint/weights.hdf5\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0959 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10322\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x556f8dbd48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.clear_session()\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1], ), name='input_layer')\n",
    "first_layer = Dense(units=8, activation='sigmoid', kernel_initializer=he_normal(seed=None), name='first_layer') (input_layer)\n",
    "second_layer = Dense(units=5, activation='sigmoid', kernel_initializer=he_normal(seed=None), name='second_layer') (first_layer)\n",
    "second_last = Dense(units=2, activation='sigmoid', kernel_initializer=he_normal(seed=None), name='second_last') (second_layer)\n",
    "output_layer = Dense(units=3, activation='sigmoid', kernel_initializer=he_normal(seed=None), name='output_layer') (second_last)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_data = (X_val, y_val),\n",
    "          batch_size=8, \n",
    "          epochs=50, \n",
    "          callbacks=[ckeckpoint, early_stoper, tensorboard],\n",
    "          verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
